{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f37be26b",
   "metadata": {},
   "source": [
    "# <center>LIC语言与智能技术竞赛</center>\n",
    "## <center>赛道三 TVB赛道</center>\n",
    "## <center>方向二 AI视频智能剪辑与解说生成 AI铰剪 技术方案</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ae7996a",
   "metadata": {},
   "source": [
    "### **一、项目介绍**\n",
    "本项目旨在基于百度 ERNIE-4.5 系列大模型，开发一款 AI 驱动的视频智能剪辑与解说生成应用系统——**AI铰剪**。\n",
    "\n",
    "该系统将融合多模态内容理解、语音识别、人声分离与说话人区分等关键技术，实现对横屏长视频（如 TVB 剧集）的粤语识别、自动化剪辑、旁白文案生成和粤语配音合成。\n",
    "\n",
    "该系统能够精准识别长视频中的关键情节与视觉亮点，输出高质量、适合移动端传播的精品短视频内容。\n",
    "\n",
    "本项目基于开源项目 NarratoAI 进行二次开发，深度重构其数据处理流程，引入多模态理解机制，融合字幕与关键帧信息，实现对视频剧情的更精准分析，并新增对粤语长视频剪辑及配音的全流程处理能力。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ce0f454",
   "metadata": {},
   "source": [
    "### **二、团队介绍**\n",
    "本团队由两名核心成员组成，目前均是暨南大学人工智能专业学硕在读，具备扎实的人工智能理论基础与工程实践能力。\n",
    "1. **组员一**\n",
    "    1. 姓名：谢志聪\n",
    "    2. 专业：人工智能\n",
    "    3. 项目经验与技能\n",
    "        1. 熟练掌握大语言模型（LLM）应用开发全流程，精通LangChain、Lazy LLM等主流开发框架；\n",
    "        2. 精通语音交互技术，涵盖语音识别（ASR）、语音合成（TTS）等领域的算法实现与工程优化。\n",
    "        3. 主导开发多智能体图书馆机器人系统，集成自然语言处理与多模态交互功能，实现高效人机协作服务。\n",
    "2. **组员二**\n",
    "    1. 姓名：郑锦辉\n",
    "    2. 专业：人工智能\n",
    "    3. 研究领域\n",
    "        1. 离线文字识别（Handwritten Text Recognition）论文\n",
    "            RVAFM: Re-parameterizing Vertical Attention Fusion Module for Handwritten Paragraph Text Recognition, Information Fusion\n",
    "        2. 人脸识别（Face Recognition）论文\n",
    "            ExpFace: Exponential Angular Margin Loss for Deep Face Recognition\n",
    "\n",
    "\n",
    "本团队具备扎实的人工智能专业基础与较强的工程实现能力，研究方向涵盖大语言模型应用、语音交互技术、计算机视觉等多个前沿领域。\n",
    "\n",
    "成员对大模型技术有深入理解和浓厚兴趣，具备较强的自主学习与攻关能力。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8388dfa5",
   "metadata": {},
   "source": [
    "### **三、技术方案解析**\n",
    "\n",
    "本系统围绕“从长视频到短视频的智能生成”目标，构建了一套以大模型为核心驱动的自动化剪辑框架。\n",
    "\n",
    "整体技术方案遵循“先理解，再创作，后合成”的设计逻辑，实现从原始音视频内容到结构化叙事输出的端到端流程。\n",
    "\n",
    "系统首先对输入的粤语长视频进行多模态预处理，提取文本（字幕）、语音与视觉（关键帧）等关键信息，构建可供大模型理解的结构化输入。\n",
    "\n",
    "随后，通过分阶段的大模型交互，逐步完成对视频主题、人物关系、画面内容与剧情发展的深度解析，并在此基础上生成具备叙事逻辑的剪辑脚本与旁白文本。\n",
    "\n",
    "最终，系统将大模型输出的抽象指令转化为可执行的剪辑操作，通过程序化方式完成视频片段的裁剪、拼接、音轨融合与格式封装，输出符合传播需求的精品短视频。\n",
    "\n",
    "本方案充分发挥大模型在语义理解与内容生成方面的优势，结合工程优化手段，在保证处理效率的同时，探索了智能剪辑在真实场景中的可行性路径。\n",
    "\n",
    "后续将详细介绍本系统技术方案，包括核心模块及其设计思路，全面展示从粤语长视频内容理解到短视频自动生成的完整技术流程。\n",
    "\n",
    "整个系统的流程图如下所示:\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"report_images/系统流程图2.svg\" alt=\"系统流程图\" style=\"width: 70%;\">\n",
    "\n",
    "\n",
    "**图 1 流程图**\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ee28c",
   "metadata": {},
   "source": [
    "系统主要包括以下五个关键模块：\n",
    "1. **用户界面模块**: 使用Streamlit库实现，用于实现便捷的人机交互及相关参数配置。\n",
    "2. **音视频前处理模块**: 负责对长视频进行预处理，涵盖音频提取、人声与背景音乐分离、语音识别、说话人区分，基于字幕实现视频切分，并提取关键帧。\n",
    "3. **大模型交互模块**: 负责与大模型的数据交互，通过分析字幕提取视频主题与人物关系；结合字幕、主题、人物关系及关键帧图像，解析各视频片段的结构与作用；最终基于整体分析结果，生成剪辑脚本与旁白。\n",
    "4. **语音合成模块**: 负责将旁白文本自动合成为高质量的粤语语音，支持自然流畅的配音输出。\n",
    "5. **视频剪辑模块**: 根据生成的剪辑脚本，对原始视频进行剪切、片段拼接，并集成合成语音、背景音乐等音视频元素，完成多轨合成与格式适配，高效生成符合平台播放要求的最终短视频。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab42b5e8",
   "metadata": {},
   "source": [
    "#### **(1)用户界面**\n",
    "本项目使用Streamlit 框架构建一个简洁直观的可视化用户界面，以提升系统的易用性与交互体验。\n",
    "\n",
    "显示效果如图所示：\n",
    "<div style=\"display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;\">\n",
    "    <img src=\"report_images/UI_screenshoot.png\" alt=\"UI界面效果图\" style=\"width: 45%; min-width: 300px;\">\n",
    "    <img src=\"report_images/UI2.png\" alt=\"UI界面效果图2\" style=\"width: 45%; min-width: 300px;\">\n",
    "    \n",
    "    \n",
    "</div>\n",
    "<center>\n",
    "\n",
    "图 2 UI效果图\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb66ece",
   "metadata": {},
   "source": [
    "可视化界面支持大模型配置、视频上传、语音识别、剪辑脚本设置、进度监控和剪辑预览等基础功能，便于用户全流程操作与管理。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bb7c9c2",
   "metadata": {},
   "source": [
    "#### **(2)音频前处理模块**\n",
    "负责对长视频进行预处理，获得长视频的字幕，同时获取视频的关键帧，为后续与大模型的交互做好数据准备。\n",
    "\n",
    "包括以下功能\n",
    "1. 音频提取\n",
    "2. 人声与背景声分离\n",
    "3. 语音识别与说话人区分\n",
    "4. 字幕合并与关键帧抽取\n",
    "\n",
    "整个流程如图所示：\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"report_images/音视频预处理.png\" alt=\"流程图\" style=\"width: 30%;\">\n",
    "\n",
    "\n",
    "**图 3 音频前处理流程图**\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4091a40",
   "metadata": {},
   "source": [
    "##### **a.音频提取**\n",
    "本项目采用 FFmpeg 进行音频提取，在分离音视频的同时，将多声道音频合并为单声道，以简化后续处理并提升语音识别的兼容性与效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08626ca0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ffmpeg -i video_path -vn -acodec pcm_s16le -ar 48000 -ac 1 -y audio_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c392089",
   "metadata": {},
   "source": [
    "##### **b. 人声与背景声分离**\n",
    "考虑到背景音乐对语音感知任务的干扰，本项目采用基于深度学习的音频分离模型 Spleeter（由 Deezer 开源），将混合音频中的人声与背景音乐进行分离，改善语音识别与语音克隆模块的输入质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e6b3d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "spleeter spleeter -p spleeter:2stems -d 2500 -o output_dir audio_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9902e",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "##### **c. 语音识别与说话人区分**\n",
    "本项目采用云服务的paraformer-v2模型进行粤语语音识别，同时进行说话人区分。\n",
    "\n",
    "最终得到的文件格式为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cc046",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "\"sentences\": [\n",
    "{\n",
    "   \"begin_time\": 0,\n",
    "   \"end_time\": 14967,\n",
    "   \"text\": \"中医其实咧会将食物分成热性嘅食物，凉性嘅食物，甚至平性嘅食物噶，当然热性嘅食物咧能够增加人体嘅温度。\",\n",
    "   \"sentence_id\": 1,\n",
    "   \"speaker_id\": 0,\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039f46f",
   "metadata": {},
   "source": [
    "##### **d. 字幕合并与关键帧抽取**\n",
    "语音识别模型输出的原始字幕以单句为单位，颗粒度过细，若直接以此作为大模型输入，将导致频繁的接口调用，显著增加计算开销。\n",
    "\n",
    "为此，本项目设计了字幕合并策略：当相邻字幕的时间间隔小于1秒且说话人一致时，将其合并为一个语义连贯的片段。\n",
    "\n",
    "该方法有效减少了输入单元数量，大幅降低了大模型的访问次数，在保障语义完整的同时提升了处理效率。\n",
    "\n",
    "为进一步增强大模型对视频内容的理解能力，充分发挥多模态分析的优势，系统在每个合并后的视频片段中提取关键帧，实现文本与视觉信息的协同输入。\n",
    "\n",
    "关键帧的提取数量根据片段时长动态调整——时长越长，提取的关键帧数量越多，确保充分覆盖该段落的视觉变化过程。\n",
    "\n",
    "这为大模型提供更具代表性的画面信息，辅助其更准确地理解剧情发展与场景上下文。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21efb792",
   "metadata": {},
   "source": [
    "#### **(3)大模型交互模块**\n",
    "这个模块是整个项目的核心模块，利用大模型的强大能力实现短视频剪辑脚本的生成，包含了以下三次与大模型的交互\n",
    "1. 主题理解与人物身份分析：基于全视频的说话人及字幕，大模型对视频整体内容进行语义解析，识别核心主题、关键事件及主要人物，并构建人物身份与关系网络，为后续剧情理解提供上下文支撑。\n",
    "2. 画面描述与剧情理解：结合关键帧图像、角色建模、视频主题对应字幕，通过**多模态大模型**对视觉内容进行描述生成，并融合文本信息实现细粒度的剧情理解，识别场景变化、情感倾向与叙事节奏。\n",
    "3. 剪辑脚本与旁白生成：在全面理解视频内容的基础上，大模型综合**唯一主题**、人物、情节发展等要素，生成结构清晰、节奏合理的短视频剪辑脚本，同时输出与画面匹配的叙述性旁白文本，为后续语音合成与视频合成提供直接输入。\n",
    "\n",
    "流程图如下所示:\n",
    "<center>\n",
    "\n",
    "<img src=\"report_images/大模型交互.png\" alt=\"大模型交互流程图\" style=\"width: 30%;\">\n",
    "\n",
    "\n",
    "**图 4 大模型交互流程图**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18d1e5",
   "metadata": {},
   "source": [
    "##### **a. 主题理解与人物身份分析**\n",
    "该环节旨在对长视频的整体内容进行宏观把握，需输入完整的字幕文本及对应的说话人信息，要求模型具备长文本理解与深层语义分析能力。\n",
    "\n",
    "由于任务涉及全局主题提取、关键事件识别以及人物身份与关系推断，对上下文长度和推理能力有较高要求。\n",
    "\n",
    "为此，本项目选用 **ERNIE-4.5-Turbo-VL-Preview** 大模型，该模型支持高达 128K tokens 的上下文窗口，能够完整承载长视频的全部字幕内容，避免信息截断。\n",
    "\n",
    "同时具备强大的多模态理解与链式推理（thinking）能力，可有效识别主题脉络、分析人物角色及其交互关系，为后续剧情理解和剪辑决策提供可靠的语义基础。\n",
    "\n",
    "部分prompt为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9c088",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "theme_extraction_prompt = f\"\"\"\n",
    "    你是一名精通粤语的、十分专业的剧情分析师，你需要完成以下任务：\n",
    "    基于以下视频的字幕内容，请同时完成两个分析任务：1) 提取视频主题 2) 分析说话人角色。\n",
    "    给出的字幕列表大大致格式为\n",
    "    片段序号 : 片段在原视频中的时间范围 ()里代表的是这个片段的持续时间\n",
    "    字幕: 这个片段包含的字幕，其中会有说话人或BGM标识。\n",
    "    其中一个具体例子\n",
    "    \n",
    "    片段1: 00:00:00,130 --> 00:00:19,980 (19.9秒)\\n\n",
    "    字幕: [Speaker 0]: 广州是广东的省府。\n",
    "    \\n---\\n\n",
    "    这表明这是片段1, 并写明了时间范围与持续时间, 而且字幕内容是Speaker0说的\n",
    "    后续可能还会有其他说话者，如Speaker 1，而[无字幕]表明的是这个片段是BGM或无字幕的片段。\n",
    "\n",
    "    {subtitle_content}\n",
    "\n",
    "    请完成以下分析：\n",
    "\n",
    "    **任务1：主题提取**\n",
    "    分析视频的核心主题，并按重要性排序。每个主题应该包含主题名称、详细描述和相关度评分。\n",
    "\n",
    "    **任务2：说话人角色分析**\n",
    "    基于字幕内容的语言风格、说话方式、对话内容，推测所有说话人在这个视频/剧集中的角色身份：\n",
    "    - 剧集角色身份（如：男主角、女主角、主要配角、次要角色、旁白、解说员等）\n",
    "    .......\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db2927",
   "metadata": {},
   "source": [
    "部分输出如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf25cf",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"themes\": [\n",
    "    {\n",
    "      \"theme_name\": \"汕头美食文化\",\n",
    "      \"theme_description\": \"视频围绕汕头特色美食展开，详细介绍了薄壳米、肠粉、牛肉火锅等当地美食及其烹饪方式，通过对话和解说展现汕头饮食文化的独特魅力。\",\n",
    "      \"relevance_score\": 0.98\n",
    "    },\n",
    "    {\n",
    "      \"theme_name\": \"汕头地理与人文背景\",\n",
    "      \"theme_description\": \"视频开头介绍了汕头的地理位置（粤东中心城市）、语言文化（接近闽南地区）及历史建筑（骑楼建筑群），为后续美食探索提供地域文化背景。\",\n",
    "      \"relevance_score\": 0.85\n",
    "    }\n",
    "  ],\n",
    "  \"speaker_analysis\": {\n",
    "    \"speaker0\": {\n",
    "      \"character_identity\": \"主持人/探索者\",\n",
    "      \"character_traits\": [\n",
    "        \"幽默风趣：使用口语化表达（如'终于直句话垃圾嘅'）和夸张语气\",\n",
    "        \"好奇心强：主动探索汕头美食并提出问题\",\n",
    "        \"文化传播者：系统介绍地域特色与饮食文化\"\n",
    "      ],\n",
    "      \"plot_importance\": \"核心人物，贯穿全视频的叙事主线\",\n",
    "      \"character_function\": \"推动剧情发展，通过实地探访和提问引导内容展开\",\n",
    "      \"screen_presence\": \"主要出镜人，持续出现并主导对话\",\n",
    "      \"relationship_dynamics\": \"主导者，与Speaker1形成问答互动关系\",\n",
    "      \"narrative_role\": \"叙事主体，串联地理介绍与美食探索\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b22def",
   "metadata": {},
   "source": [
    "##### **b. 画面描述与剧情理解**\n",
    "相较于第一阶段的长上下文理解，本环节侧重于局部片段的多模态语义对齐，输入为“关键帧图像 + 对应字幕 + 主题/人物上下文提示”。\n",
    "\n",
    "任务目标包括：生成画面描述、识别角色行为、推断情感氛围与剧情作用。\n",
    "\n",
    "考虑到该步骤需对数十甚至上百个视频片段逐一调用模型，访问次数显著增加，因此未采用高延迟的长文本模型，而是选用轻量化且专为视觉语言任务优化的 ERNIE-4.5-VL-28B-A3B 模型。\n",
    "\n",
    "部分Prompt为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db541",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_prompt = f\"\"\"\n",
    "你是一名资深的TVB剧集分析师，拥有丰富的粤语影视剧观看经验。现在需要你基于提供的信息进行专业的剧情分析。\n",
    "\n",
    "我将为你提供整个长视频的背景信息以及当前片段的具体内容，请你完成深度的剧情分析工作。\n",
    "\n",
    "## 整个长视频的核心主题信息：\n",
    "{themes_info}\n",
    "\n",
    "## 整个长视频中所有说话人的角色分析：\n",
    "以下是各个说话人（如speaker0、speaker1等）的详细信息，可作为剧情分析的重要参考。当前片段的具体说话人将在下方\"当前片段信息\"中标明。\n",
    "{speaker_info}\n",
    "\n",
    "## 当前片段信息：\n",
    "- 时间段：{timestamp}\n",
    "- 持续时长：{duration:.2f} 秒\n",
    "- 说话人与字幕内容：\"{subtitle_text}\"\n",
    "\n",
    "## 视觉资料：\n",
    "我还将提供 {len(keyframe_paths)} 张从这个片段中截取的关键帧图像，这些图片按时间顺序排列，请结合这些视觉信息进行画面理解与剧情梳理。\n",
    "\n",
    "## 分析任务：\n",
    "请仔细分析视频帧内容，并结合字幕文本、主题信息和说话人角色特征，完成以下四项任务：\n",
    "\n",
    "1. **画面理解**：详细描述画面中的主要内容，包括人物形象、动作行为、场景环境等视觉元素。\n",
    "\n",
    "2. **剧情梳理**：基于画面和字幕内容\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb4879",
   "metadata": {},
   "source": [
    "部分输出如下: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09302111",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "## 片段 1\n",
    "- **时间范围**: 00:00:05,310 --> 00:00:25,010\n",
    "- **当前片段的持续时间**: 19.70秒\n",
    "- 原始字幕(带说话人与BGM标识): [Speaker 0]: 我亦都可以发神释放我你在平台上我面你启航计较那么多，为什么从头发现我不要再害怕，可不可相信最绝的感觉的时候再回头看。\n",
    "- 画面描述: 画面展示了一名背着蓝色外卖箱的女生背影，她走在拥挤的街道上，身旁有行人、公交车等繁忙的城市景象。随后画面切换到骑摩托车的场景，也有外卖员的身影。之后又展示了男生唱歌、几个人在逼仄的巷子里搬东西、骑车、扔东西等场景，最后是大家聚在一起吃外卖的热闹场景。\n",
    "- 关键要素: 繁忙的街道、外卖员、吃外卖的青年们\n",
    "- 内容分析: 这个片段承接前文，展示了角色们送外卖的日常，最后众人聚在一起吃外卖的场景，凸显了角色间亲密的关系，为后文大家重头再来的决定做铺垫。\n",
    "- 片段总结: 片段展示了角色们送外卖的日常和聚在一起吃外卖的热闹场景，凸显了角色间亲密的关系。\n",
    "- 角色表现: speaker0代表外卖员群体，作为背景音，表达了外卖员的心声，鼓励大家不要害怕，大胆去闯，去释放自己。speaker1作为女主角，虽然并未在画面中出声，但外卖员们重头再来的决定，离不开她的鼓励与带领。片尾众人聚在一起吃外卖的热闹场景，也侧面体现出speaker1作为核心人物，在团队中起到了凝聚的作用。\n",
    "- 相关主题: 个人成长与自我价值实现 (相关度: 0.95)、社会压力与代际差异 (相关度: 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542da6ec",
   "metadata": {},
   "source": [
    "##### **c. 剪辑脚本与旁白生成**\n",
    "本阶段综合前序各环节的分析结果，生成最终的剪辑脚本与旁白。由于需处理全部片段的全局信息，对上下文长度和推理能力要求较高。\n",
    "\n",
    "因此选用支持长文本输入并具备思维链能力的 ERNIE-4.5-Turbo-VL-Preview 模型，确保输出内容逻辑清晰、结构完整。\n",
    "\n",
    "部分Prompt如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9580c7d",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    " # 粤语长片短视频剪辑任务\n",
    "本次剪辑要输出的短视频主题是 ${theme} 具体描述为 ${theme_description}。\n",
    "\n",
    "## 每个长视频小分段提供的内容如下:\n",
    "<video_content>\n",
    "${video_frame_description}\n",
    "</video_content>\n",
    "\n",
    "重要提醒：video_content中包含了长片的所有片段，\n",
    "但你需要从中精选出最符合主题的片段，而不是处理每一个片段。\n",
    "重点关注片段与主题的相关性、内容价值和视觉效果。          \n",
    "\n",
    "## 专业剪辑核心要素\n",
    "\n",
    "### 1. 主题导向的片段筛选（最重要）\n",
    "严格围绕指定主题进行片段选择，这是剪辑的核心\n",
    "\n",
    "#### 片段筛选标准\n",
    "- 主题相关性：片段内容必须与指定主题高度相关（相关性80%以上）\n",
    "- 内容价值：选择信息密度高、有教育意义或娱乐价值的片段"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b29590",
   "metadata": {},
   "source": [
    "大模型将会输出**格式化**的剪辑脚本及需要配音的旁白："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a553cb",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"_id\": 3,\n",
    "  \"timestamp\": \"00:03:15,730-00:03:20,000\",\n",
    "  \"picture\": \"薄壳米炒韭菜花特写，绿衣男子品尝后竖拇指\",\n",
    "  \"narration\": \"薄壳米炒韭菜花，镬气够，鲜甜加爽脆，每一口都令人回味！\",\n",
    "  \"duration\": 4.27,\n",
    "  \"total_duration\": 18.03,\n",
    "  \"OST\": 0\n",
    "},\n",
    "{\n",
    "  \"_id\": 4,\n",
    "  \"timestamp\": \"00:03:56,800-00:04:03,000\",\n",
    "  \"picture\": \"咸蛋黄薄壳米特写，绿衣男子品尝后作享受状\",\n",
    "  \"narration\": \"咸蛋黄爆裹薄壳米，外酥内嫩，咸香可口，真係流晒口水啊！\",\n",
    "  \"duration\": 6.2,\n",
    "  \"total_duration\": 24.23,\n",
    "  \"OST\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9524e81",
   "metadata": {},
   "source": [
    "#### **(4) 语音合成模块** \n",
    "语音合成模块将剪辑脚本中的旁白文本转化为粤语语音。\n",
    "\n",
    "项目采用 MiniMax 的 speech-01-hd 模型进行高保真语音生成，并支持基于原始视频中人物语音的音色克隆。\n",
    "\n",
    "系统自动从字幕定位语音片段，筛选出约15秒的高质量候选段，优先保留前后无字幕、语音清晰的片段，并确保每位说话人都有代表性样本（如果其说话时长≥15秒）。\n",
    "\n",
    "最终由创作者人工选定最优片段用于音色提取，实现个性化配音。\n",
    "\n",
    "音色克隆的过程大致如图所示：\n",
    "<center>\n",
    "\n",
    "<img src=\"report_images/音频克隆展示1.png\" alt=\"大模型交互流程图\" style=\"width: 50%;\">\n",
    "<img src=\"report_images/音频克隆展示2.png\" alt=\"大模型交互流程图\" style=\"width: 50%;\">\n",
    "\n",
    "\n",
    "**图 5 音频克隆展示**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857dcc0",
   "metadata": {},
   "source": [
    "#### **(5) 视频剪辑模块**\n",
    "\n",
    "本模块根据剪辑脚本，将原始视频片段、合成配音、背景音乐和字幕等元素进行剪辑拼接，最终生成目标短视频。\n",
    "\n",
    "由于涉及复杂的音视频操作，系统采用 Python 库 MoviePy 实现自动化处理，其支持精准裁剪、多轨合成与格式封装。\n",
    "\n",
    "流程包括：\n",
    "1. 按时间轴裁剪视频片段；\n",
    "2. 融合原声与合成配音，生成多轨音频；\n",
    "3. 将视频片段与完整音频同步拼接，输出最终成片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4bf1c",
   "metadata": {},
   "source": [
    "#### **(6) 其余部分**\n",
    "\n",
    "1. 为提升处理速度，系统采用支持 GPU 加速的 FFmpeg 进行音视频解码与关键帧提取，并在多处引入并行与并发优化：关键帧抽取使用多进程并行处理多个视频片段；大模型 API 请求通过协程实现高并发调用，显著缩短等待时间，整体处理效率显著提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071e55f",
   "metadata": {},
   "source": [
    "### **四、未来展望**\n",
    "\n",
    "尽管系统已成功实现从长视频输入到短视频自动生成的全流程贯通，各项模块协同运行稳定，但仍存在若干可优化的环节，当前主要问题如下：\n",
    "\n",
    "1. 粤语语音识别准确率有待提升\n",
    "    在本项目的处理流程中，字幕作为大模型理解视频内容的核心输入，其质量直接影响后续的主题分析、人物识别与剪辑脚本生成效果。然而，在实际应用中，粤语语音识别的准确性仍面临一定挑战：\n",
    "    - 部分发音口音较重或语速较快，导致识别错误；\n",
    "    - 背景音乐、环境噪声等干扰因素影响音频纯净度；\n",
    "    - 粤语中存在较多口语化表达、俚语及低频词汇，现有语音识别模型对此类内容覆盖不足。\n",
    "    - 上述问题可能导致生成的字幕出现错别字、断句错误或语义偏差，进而传导至大模型交互环节，影响主题理解与剧情分析的准确性，甚至引发剪辑逻辑偏差。\n",
    "2. 尽管本项目通过多层次输入策略（从纯文本字幕 → 文本+关键帧图像）逐步引导大模型理解视频内容，在一定程度上提升了语义感知能力，但在实际实现过程中，仍面临若干影响理解深度的技术瓶颈：\n",
    "    - 关键帧抽取策略的局限性\n",
    "        为实现画面内容的多模态分析，系统需对视频进行抽帧处理，将视觉信息与对应字幕联合输入大模型。然而，当前缺乏精准判断“真正关键帧”的机制——例如能体现情节转折、人物情绪变化或重要动作的帧。现有方法主要依赖时间均匀采样或基于镜头切换的简单检测，为避免遗漏重要信息，只能通过提高抽帧频率来增强覆盖度，但这带来了计算开销上升与冗余输入增多的问题，且并不能从根本上保证语义关键帧的捕获。\n",
    "    - 分段并发处理带来的上下文割裂\n",
    "        为了提升处理效率，系统在“画面+字幕理解”阶段采用并发方式对各视频片段独立调用大模型分析。该策略显著加快了响应速度，但也将原本连续的叙事流人为割裂，忽略了相邻片段之间的强语义关联（如伏笔、情绪递进、对话延续等）。虽然项目前期通过全局字幕分析构建了整体主题与人物关系，一定程度上缓解了上下文缺失问题，但从理论层面看，局部独立推理仍可能导致对剧情脉络的片面理解或误判。\n",
    "    - 字幕合并策略对细节表达的削弱\n",
    "        为降低大模型调用次数、控制成本与延迟，系统引入了字幕合并机制：当相邻字幕由同一说话人发出且时间间隔较短时，将其合并为一个输入单元。该策略基于“同一说话人连续发言通常处于同一场景”的合理假设，有效减少了请求频次。然而，这一操作也可能模糊剧情细节，例如忽略微小的表情变化、语气转折或背景动作，导致大模型难以捕捉细腻的情感节奏或隐含信息，影响最终剪辑脚本的表现力与准确性。\n",
    "3. 未进行对系统各个环节的测试与改善\n",
    "    由于本次项目开发周期紧张，团队虽在设计阶段构建了完整的数据流程与系统架构，并对各模块功能进行了初步验证，但尚未开展系统性的控制变量实验与模块性能评估。目前各环节的模型选型与参数设置主要基于技术调研与经验判断，缺乏充分的实证支持。\n",
    "\n",
    "\n",
    "随着大模型技术的不断进步，智能剪辑正成为内容创作的重要发展方向。尽管目前相关应用（如 NarratoAI）仍处于初级阶段，但其发展潜力巨大。\n",
    "我们相信，未来在更强模型与更优算法的驱动下，智能剪辑将迎来质的突破。\n",
    "本项目是一次有益的探索，我们团队也将持续深耕相关领域，不断优化与迭代，推动系统向更高水平迈进。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
