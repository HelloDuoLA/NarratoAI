{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f37be26b",
   "metadata": {},
   "source": [
    "# <center>LIC语言与智能技术竞赛</center>\n",
    "## <center>赛道三 TVB赛道</center>\n",
    "## <center>方向二 AI视频智能剪辑与解说生成 技术方案</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ae7996a",
   "metadata": {},
   "source": [
    "### 一、项目介绍\n",
    "本项目旨在基于百度 ERNIE-4.5-VL 视觉语言大模型，开发一款 AI 驱动的视频智能剪辑与解说生成应用系统——AI铰剪。\n",
    "该系统将融合多模态内容理解、语音识别与合成以及图像生成等关键技术，实现对横屏长视频（如 TVB 剧集）的粤语识别、自动化剪辑、解说文案生成、粤语配音合成及封面图像创作。\n",
    "该系统能够精准识别视频中的关键情节与视觉亮点，自动完成从横屏到竖屏的构图适配与内容重构，输出高质量、适合移动端传播的精品短视频内容。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ce0f454",
   "metadata": {},
   "source": [
    "### 二、团队介绍\n",
    "本团队由两名核心成员组成，均就读于暨南大学人工智能专业硕士研究生，具备扎实的理论基础与工程实践能力。\n",
    "1. **组员一**\n",
    "    1. 姓名：谢志聪\n",
    "    2. 专业：人工智能\n",
    "    3. 项目经验与技能\n",
    "        1. 熟练掌握大语言模型（LLM）应用开发全流程，精通LangChain、Lazy LLM等主流开发框架；\n",
    "        2. 精通语音交互技术，涵盖语音识别（ASR）、语音合成（TTS）等领域的算法实现与工程优化。\n",
    "        3. 主导开发多智能体图书馆机器人系统，集成自然语言处理与多模态交互功能，实现高效人机协作服务。\n",
    "2. **组员二**\n",
    "    1. 姓名：郑锦辉\n",
    "    2. 专业：人工智能\n",
    "    3. 研究领域\n",
    "        1. 离线文字识别（Handwritten Text Recognition）论文\n",
    "            RVAFM: Re-parameterizing Vertical Attention Fusion Module for Handwritten Paragraph Text Recognition, Information Fusion\n",
    "        2. 人脸识别（Face Recognition）论文\n",
    "            ExpFace: Exponential Angular Margin Loss for Deep Face Recognition\n",
    "\n",
    "本团队具备扎实的人工智能专业基础与较强的工程实现能力，研究方向涵盖大语言模型应用、语音交互技术、计算机视觉等多个前沿领域。成员对大模型技术有深入理解和浓厚兴趣，具备较强的自主学习与攻关能力。项目期间将有充足时间投入研发工作，能够积极应对技术挑战，确保项目顺利推进并取得预期成果。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8388dfa5",
   "metadata": {},
   "source": [
    "### 三、产品设计\n",
    "本章将详细介绍本系统的核心模块及其设计思路，全面展示从粤语长视频内容理解到短视频自动生成的完整技术流程。系统主要包括以下八个关键组成部分：**用户界面模块**，用于实现便捷的人机交互与参数配置；**语音识别模块**，负责提取视频中的音频语义信息；**剧情理解与主题理解模块**，基于多模态输入对视频内容进行深度分析并提炼核心主题；**剪辑脚本生成模块**，依据主题驱动机制定位关键片段并生成配套解说文案；**语音合成模块**，实现高质量粤语配音的自动输出；**封面生成模块**，结合主题特征生成具有视觉吸引力的短视频封面；**视频剪辑模块**，完成最终短视频的格式适配与高效合成。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab42b5e8",
   "metadata": {},
   "source": [
    "#### (1)用户界面\n",
    "本项目计划采用 Streamlit 框架构建一个简洁直观的可视化用户界面（UI），以提升系统的易用性与交互体验。界面将支持大模型配置、视频上传、剪辑方式选择、处理进度展示及剪辑预览等基础功能，整体风格参考当前主流 AI 工具的设计范式，力求操作便捷、响应高效，便于后续测试与推广应用，效果如图所示：\n",
    "\n",
    "图 1 UI界面效果图 ![img](docs/image.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bb7c9c2",
   "metadata": {},
   "source": [
    "#### (2)语音识别\n",
    "\n",
    "本项目所采用的 ERNIE-4.5-VL 视觉语言大模型虽不支持音频信号的直接输入，而视频中的对白与音效往往包含大量关于人物互动与剧情发展的关键信息。为充分挖掘视频内容语义，项目引入高性能语音识别（ASR）模型，对原始视频中的音频内容进行识别，生成高精度字幕文本。该文本将作为后续剧情理解、剪辑主题提取与剪辑策略生成的重要语义依据，从而实现对视频内容更全面、深入的多模态分析与重构。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e88c95",
   "metadata": {},
   "source": [
    "#### (3)剪辑脚本生成\n",
    "\n",
    "为提升短视频生成的质量与传播价值，本项目在内容生成过程中兼顾对原始粤语视频的准确呈现与主题一致性表达。一方面，要求生成的短视频能够忠实反映原始视频的核心情节与语义信息；另一方面，期望短视频具备统一的主题导向，从而形成具有辨识度和传播力的内容产品。为此，项目拟从画面与字幕两个维度出发，对输入视频进行多模态剧情理解，确保大模型能够全面、准确地捕捉视频内容。在此基础上，系统将自动归纳出视频所包含的多个潜在主题，并以此作为后续剪辑与解说生成的引导依据。通过主题驱动的方式，辅助模型从原始视频中筛选出与主题高度相关的片段，提升最终输出短视频内容的连贯性与聚焦性。同时，该主题体系也将用于指导解说文案的生成，使其围绕明确的核心主旨展开，进一步增强短视频整体的表现力与传播效果。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a661e6e",
   "metadata": {},
   "source": [
    "##### **1.剧情理解**\n",
    "    \n",
    "本项目将从视频画面与音频两个模态出发，对视频剧情内容进行系统性理解。尽管视频画面能够提供丰富的视觉语义信息，但单帧图像缺乏时序上下文，难以反映连续动作与情节发展；而多帧画面之间的时序建模又受限于当前大模型在动态推理方面的能力边界，存在一定的不确定性。相比之下，语音识别生成的字幕文本不仅包含关键语义内容，还天然具备时间戳信息，能够为视频内容理解提供可靠的时序参考。\n",
    "因此，本项目采用“以文助画”的思路，利用视觉语言大模型对关键帧进行文字描述，并结合带有时间信息的字幕文本，实现对视频内容的多模态、有时序感知的理解与归纳。在此基础上，系统将提取视频中蕴含的多个潜在主题，为后续剪辑策略制定和解说文案生成提供结构化语义支撑，从而提升短视频内容的一致性与叙事逻辑性。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "517da45c",
   "metadata": {},
   "source": [
    "- 1\\) 画面理解\n",
    "\n",
    "    针对视频画面所蕴含的丰富视觉信息，本项目利用多模态大模型结合字幕对关键帧内容进行语义分析与归纳，生成对每一帧画面的文字描述。借助大模型强大的推理能力，系统能够从视觉层面提取视频的主要情节与关键元素，实现对视频内容的初步结构化表达。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "225fcc48",
   "metadata": {},
   "source": [
    "- 2\\) 主题理解\n",
    "    在获得画面文字描述与语音识别字幕的基础上，系统进一步引导大模型对多模态信息进行联合分析，从中提炼出视频各片段所体现的核心主题，如“美食”、“运动”、“养生”等。该主题提取过程不仅有助于构建视频内容的知识结构，也为后续剪辑策略制定与解说文案生成提供了明确的语义导向。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06016783",
   "metadata": {},
   "source": [
    "##### **2.剪辑脚本生成**\n",
    "在视频主题提炼的基础上，系统以主题为核心线索，引导视觉语言大模型在原始视频中识别并定位与之内容匹配的相关片段，实现语义驱动的智能剪辑。同时，系统结合所选片段的内容特征，自动生成与其情境相符、风格一致的粤语解说文案。\n",
    "最终输出的剪辑脚本将包含多个关键要素：核心主题、对应片段的时间节点、画面描述以及配套解说文字，形成结构清晰、语义连贯的视频编辑指导文件，为后续的视频合成与配音生成提供坚实支撑。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68d7bfc6",
   "metadata": {},
   "source": [
    "#### (4)语音合成\n",
    "本项目将采用先进的粤语语音合成大模型，实现高质量、自然流畅的配音生成。与传统基于规则或统计模型的 TTS（Text-to-Speech）系统相比，基于大模型的语音合成技术在语音自然度、情感表达能力以及多音字、语境适应性等方面具有显著优势。大模型能够更准确地理解文本语义，并结合上下文信息进行语音韵律、语调和停顿的智能调控，使生成的粤语语音更加贴近真人发音，具备更强的表现力与沉浸感。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2eec0c20",
   "metadata": {},
   "source": [
    "#### (5)封面生成\n",
    "在短视频传播过程中，封面图像作为吸引用户注意力的第一视觉入口，具有至关重要的作用。为提升短视频的点击率与传播效果，本项目将结合视频内容所提炼出的核心主题，从视频中提取具有代表性的视觉元素，并基于文生图与图生图技术，生成风格统一、视觉吸引力强的封面图像。\n",
    "系统将利用大模型对提示词的强理解能力，结合当前短视频平台流行的视觉风格与审美趋势，自动生成适配不同主题内容的高质量封面图，确保其在移动端展示中的辨识度与吸引力，从而有效提升视频内容的传播力与用户触达效率。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b15c6133",
   "metadata": {},
   "source": [
    "#### (6)视频剪辑\n",
    "在视频剪辑阶段，系统将依据生成的剪辑脚本，自动提取原始视频中与主题匹配的片段，并将其与生成的粤语配音、字幕及封面图像进行合成，最终输出完整的短视频内容。为适配移动端播放需求，系统将统一调整视频分辨率至竖屏格式，确保视觉呈现效果符合短视频平台的传播规范。\n",
    "同时，项目将引入基于硬件加速的视频处理技术，显著提升视频编解码与合成效率，缩短处理时间，优化整体系统的响应速度与用户使用体验，从而实现高质量、高效率的一站式短视频生成流程。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77d191ad",
   "metadata": {},
   "source": [
    "### 四、数据处理思路\n",
    "本章将介绍系统的数据处理总体思路，重点说明如何从长视频输入中生成多个短视频输出的整体流程，相关处理步骤与系统架构如下图所示：\n",
    "\n",
    "![img](docs/image.svg) \n",
    "\n",
    "图 2 数据处理流程图\n",
    "\n",
    "系统以粤语长视频为输入，首先进行音视频分离，得到视频流与音频流。**音频部分**经人声分离后，使用**语音识别**生成带时间戳的粤语字幕，作为后续画面描述、主题提取与剪辑脚本生成的重要文本依据。在视频支路，将提取视频的关键帧，包括固定间隔抽取或者画面变化阈值抽取。对于**视频部分**，系统将提取关键帧，提取方式包括固定时间间隔采样或基于画面变化阈值的动态检测。随后，**画面描述大模型**结合关键帧图像与音频支路生成的字幕信息，进行长视频的多模态剧情理解，并将分析结果传递至主题生成大模型与剪辑脚本生成大模型，支撑后续内容组织与剪辑决策。\n",
    "**短视频主题生成大模型**与**剪辑脚本生成大模型**在接收多模态分析结果的基础上，还将引入用户定义的剪辑方式Prompt，以支持多样化剪辑风格的生成。**剪辑脚本大模型**生成以主题为核心驱动，根据不同主题特征及剪辑风格要求，生成对应的剪辑脚本，并输出相应的配音文本。该文本通过粤语配音生成大模型生成粤语配音片段。最终，**剪辑模块**根据脚本内容，整合原始视频片段与生成的配音，完成短视频的最终输出。\n",
    "此外，**封面生成大模型**将结合剪辑主题与解说文字内容，参考关键视频帧及热门封面样式，自动生成符合短视频风格的封面图像，提升视频吸引力与平台推荐效果。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edf2fd17",
   "metadata": {},
   "source": [
    "### 五、技术实现路径\n",
    "本章将围绕系统的核心功能模块，依次介绍关键技术的实现方法与流程，涵盖语音识别与合成、大模型部署与调用、剧情理解、剪辑脚本生成、封面生成以及视频剪辑等环节，以全面展示系统的构建逻辑与技术架构。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "936ae2af",
   "metadata": {},
   "source": [
    "#### (1)语音识别\n",
    "在语音识别部分，本项目采用 Spleeter 音源分离算法对提取的音频进行人声与背景音乐的分离，避免背景音乐对后续环节产生影响。随后将经音源分离后的人声部分输入基于 Whisper 构建的粤语语音识别模型，执行自动语音识别任务。识别结果以时间戳形式输出，并组织为标准的 SRT 字幕文件格式，供后续视频剪辑、解说生成及多模态分析模块使用。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47e7bb51",
   "metadata": {},
   "source": [
    "#### (2)语音合成\n",
    "在语音合成部分，本项目依托于粤语语音合成大模型，旨在实现高质量、自然流畅的配音生成。在系统初期阶段，将通过多轮参数调试与听感评估，选取具有较强通用性的音色、语调及语速等语音参数，以构建适配多种视频内容类型的基线配音风格。\n",
    "在后续优化阶段，系统将利用大模型对当前视频片段的内容语义与情绪特征进行分析，自动匹配并生成最适宜的语音参数组合，包括但不限于音色情感倾向、语调起伏模式与语速节奏变化，从而提升配音与画面内容之间的契合度与沉浸感。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f7022d6",
   "metadata": {},
   "source": [
    "#### (3)大模型部署与调用\n",
    "本项目支持本地部署与云端调用两种大模型使用方式。本地部署方面，已基于 Fast Deploy 框架在 A100 主机上成功部署 ERNIE-4.5-VL-28B-A3B 模型。云端调用方面，系统可以通过 Python SDK 接口调用 AI Studio 与 百度智能云 API ，实现远程推理服务的接入。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "619f732c",
   "metadata": {},
   "source": [
    "#### (4)剪辑脚本生成\n",
    "本系统依托多模态大模型，实现对输入粤语长视频的内容理解、主题归纳及剪辑脚本生成。具体流程如下："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f65369a",
   "metadata": {},
   "source": [
    "##### **1.剧情理解**\n",
    "- 1\\) 画面内容理解\n",
    "    \n",
    "    系统通过 OpenCV 库对输入视频进行关键帧提取，支持两种提取方式：基于固定时间间隔的采样或基于画面变化阈值的动态检测。随后，将对应时间段内的字幕文件与关键帧共同输入至**画面描述大模型**（通过设定合适的 Prompt 对基座模型进行功能引导，使其具备对视频画面进行准确描述的能力）中，以实现对视频内容的语义理解与结构化分析。最终输出的描述信息将与字幕文件保持时间对齐，并以结构化形式存储，供后续主题归纳与剪辑脚本生成模块使用。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1c9b0e6",
   "metadata": {},
   "source": [
    "- 2\\) 主题理解\n",
    "\n",
    "    基于前述环节提取的结构化剧情片段数据，并结合预定义的多种剪辑方式（每种剪辑方式对应不同的 Prompt 指令），系统利用**主题生成大模型**（通过设定合适的 Prompt 对基座模型进行功能引导，使其具备准确概括视频主题的能力）实现对长视频内容的多主题归纳，从而为后续剪辑脚本的生成提供语义基础与内容导向。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "808a8c51",
   "metadata": {},
   "source": [
    "##### **2.剪辑脚本生成**\n",
    "结合前述环节提取的结构化剧情片段数据、短视频主题以及不同剪辑需求，**剪辑脚本生成大模型**(通过设定合适的 Prompt 对基座模型进行功能引导，使其具备主题片段提取、排序的能力）能够提取出符合当前主题的视频片段信息，并最终将这些信息整合为预定义格式的剪辑脚本，以指导后续剪辑流程的执行。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c8c9f7e",
   "metadata": {},
   "source": [
    "#### (5)封面生成\n",
    "在封面生成环节，本项目将结合短视频的主题内容及当前流行的视频风格Prompt，生成适配的视觉封面。系统调用百度智能云“一念”AI作图服务，实现风格化封面图像的自动化生成，提升视频吸引力与平台推荐效果。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64d14662",
   "metadata": {},
   "source": [
    "#### (6)视频剪辑\n",
    "在视频剪辑阶段，系统依据预定义格式的剪辑脚本，对原始视频片段与生成的粤语配音进行时间轴对齐、裁剪与合成，最终输出多个符合移动端播放习惯的短视频。\n",
    "为实现高效且灵活的视频编辑，本系统采用 MoviePy 与 FFmpeg 两种工具协同处理："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdacb942",
   "metadata": {},
   "source": [
    "- 1\\) **MoviePy** ：主要用于基于时间轴的视频剪辑操作，包括片段裁剪、拼接、转场效果添加等，支持 Python 脚本控制，便于集成至整体自动化流程；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1f99b60",
   "metadata": {},
   "source": [
    "- 2\\) **FFmpeg** ：负责底层视频编码转换、分辨率调整、帧率控制等任务，确保输出视频在保持高质量的同时适配移动端播放需求。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f294dc08",
   "metadata": {},
   "source": [
    "通过 MoviePy 的高层逻辑控制与 FFmpeg 的底层优化能力相结合，系统能够高效完成从原始视频到竖屏短视频的智能剪辑与格式转换，满足短视频平台的内容发布与分发要求。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
